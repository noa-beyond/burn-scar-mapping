{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Εισαγωγή βιβλιοθηκών"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykml import parser\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point, Polygon\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlretrieve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Συνάρτηση για το κατέβασμα των KML από το https://sentinel.esa.int/web/sentinel/copernicus/sentinel-2/acquisition-plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_kml():\n",
    "    KML_url = 'https://sentinel.esa.int/web/sentinel/copernicus/sentinel-2/acquisition-plans'\n",
    "    base_url = 'https://sentinel.esa.int/'\n",
    "    response = requests.get(KML_url)\n",
    "    sentinel_types = ['sentinel-2a', 'sentinel-2b']\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print('Response OK!')\n",
    "\n",
    "        # Parse the HTML content\n",
    "        html_content = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        for sentinel_type in sentinel_types:\n",
    "            elements = html_content.find_all(class_=sentinel_type)\n",
    "\n",
    "            if elements:\n",
    "                for element in elements:\n",
    "                    # Find all links within the element\n",
    "                    links = element.find_all('a')\n",
    "\n",
    "                    for link in links:\n",
    "                        if 'href' in link.attrs:\n",
    "                            file_url = link['href']\n",
    "                            link_text = link.get_text(strip=True)\n",
    "                            print(f'Downloading {link_text} from {base_url + file_url}')\n",
    "\n",
    "                            # Construct the file name and full URL\n",
    "                            file_name = os.path.basename(file_url) + '.kml'\n",
    "                            full_file_url = base_url + file_url\n",
    "                            \n",
    "                            # Download the file\n",
    "                            urlretrieve(full_file_url, file_name)\n",
    "                            print(f'File downloaded as {file_name}\\n')\n",
    "                        else:\n",
    "                            print('No href found for this link.')\n",
    "            else:\n",
    "                print(f'No elements found for {sentinel_type}')\n",
    "    else:\n",
    "        print('Response not OK!!!')\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response OK!\n",
      "Downloading 22 August - 09 September 2024 from https://sentinel.esa.int//documents/d/sentinel/s2a_mp_acq__kml_20240822t120000_20240909t150000\n",
      "File downloaded as s2a_mp_acq__kml_20240822t120000_20240909t150000.kml\n",
      "\n",
      "Downloading 08 - 26 August 2024 from https://sentinel.esa.int//documents/d/sentinel/s2a_mp_acq__kml_20240808t090000_20240826t120000\n",
      "File downloaded as s2a_mp_acq__kml_20240808t090000_20240826t120000.kml\n",
      "\n",
      "Downloading 15 August - 02 September 2024 from https://sentinel.esa.int//documents/d/sentinel/s2b_mp_acq__kml_20240815t120000_20240902t150000\n",
      "File downloaded as s2b_mp_acq__kml_20240815t120000_20240902t150000.kml\n",
      "\n",
      "Downloading 03 - 19 August 2024 from https://sentinel.esa.int//documents/d/sentinel/s2b_mp_acq__kml_20240803t120000_20240819t150000\n",
      "File downloaded as s2b_mp_acq__kml_20240803t120000_20240819t150000.kml\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_kml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Συνάρτηση μετατροπής συντεταγμένων σε πολύγωνο"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert coordinates to a Polygon object\n",
    "def coordinates_to_polygon(coordinates):\n",
    "    # Coordinates are typically in the form \"lon,lat,alt lon,lat,alt ...\"\n",
    "    points = []\n",
    "    for coord in coordinates.split():\n",
    "        lon, lat, _ = map(float, coord.split(\",\"))\n",
    "        points.append((lon, lat))\n",
    "    return Polygon(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Συνάρτηση εξαγωγής δεδομένων απο KML σε GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recursively extract placemarks and save to GDB\n",
    "def extract_placemarks_to_gdb(folder, gdf_data=[]):\n",
    "    if hasattr(folder, 'Placemark'):\n",
    "        for placemark in folder.Placemark:\n",
    "            data = {\n",
    "                'name': placemark.name.text if hasattr(placemark, 'name') else \"No Name\",\n",
    "                'geometry': coordinates_to_polygon(\n",
    "                    placemark.Polygon.outerBoundaryIs.LinearRing.coordinates.text\n",
    "                ) if hasattr(placemark, 'Polygon') else None,\n",
    "                'styleUrl': placemark.styleUrl.text if hasattr(placemark, 'styleUrl') else None,\n",
    "                'visibility': int(placemark.visibility.text) if hasattr(placemark, 'visibility') else None,\n",
    "                'begin': placemark.TimeSpan.begin.text if hasattr(placemark, 'TimeSpan') else None,\n",
    "                'end': placemark.TimeSpan.end.text if hasattr(placemark, 'TimeSpan') else None,\n",
    "            }\n",
    "\n",
    "            # Extract ExtendedData fields\n",
    "            if hasattr(placemark, 'ExtendedData'):\n",
    "                for data_field in placemark.ExtendedData.Data:\n",
    "                    data_name = data_field.get('name')\n",
    "                    data_value = data_field.value.text\n",
    "                    data[data_name] = data_value\n",
    "\n",
    "            gdf_data.append(data)\n",
    "            \n",
    "    if hasattr(folder, 'Folder'):\n",
    "        for subfolder in folder.Folder:\n",
    "            extract_placemarks_to_gdb(subfolder, gdf_data)\n",
    "            \n",
    "    return gdf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mpraktiki_noa\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mpraktiki_scripts\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124msentinel_acquisition_plans\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124ms2a_mp_acq__kml_20240822t120000_20240909t150000.kml\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 4\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241m.\u001b[39mparse(f)\u001b[38;5;241m.\u001b[39mgetroot()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Extract all placemarks and their geometries\u001b[39;00m\n\u001b[0;32m      7\u001b[0m gdf_data \u001b[38;5;241m=\u001b[39m extract_placemarks_to_gdb(root\u001b[38;5;241m.\u001b[39mDocument)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'parser' is not defined"
     ]
    }
   ],
   "source": [
    "# Main script\n",
    "filename = 'D:\\\\praktiki_noa\\\\praktiki_scripts\\\\sentinel_acquisition_plans\\\\s2a_mp_acq__kml_20240822t120000_20240909t150000.kml'\n",
    "with open(filename) as f:\n",
    "    root = parser.parse(f).getroot()\n",
    "\n",
    "# Extract all placemarks and their geometries\n",
    "gdf_data = extract_placemarks_to_gdb(root.Document)\n",
    "print(len(gdf_data))\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "# Specify columns including dynamic fields extracted from ExtendedData\n",
    "columns = ['name', 'geometry', 'styleUrl', 'visibility', 'begin', 'end'] + list({key for row in gdf_data for key in row.keys() if key not in ['name', 'geometry', 'styleUrl', 'visibility', 'begin', 'end']})\n",
    "\n",
    "# Create the GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(gdf_data, columns=columns)\n",
    "\n",
    "# Print all placemarks' names and coordinates\n",
    "print(\"Placemarks: \\n\", len(gdf))\n",
    "\n",
    "print(gdf)\n",
    "\n",
    "# Διαγραφή των διπλότυπων εγγραφών, κρατώντας μόνο την πρώτη εμφάνιση\n",
    "# Εδώ χρησιμοποιούμε τη στήλη 'name' ως κριτήριο, μπορείς να προσθέσεις περισσότερες στήλες αν χρειάζεται\n",
    "gdf_unique = gdf.drop_duplicates(subset= gdf.columns)\n",
    "\n",
    "# Εμφάνιση του GeoDataFrame μετά την αφαίρεση των διπλότυπων\n",
    "print(\"\\n GeoDataFrame μετά την αφαίρεση των διπλότυπων:\")\n",
    "print(gdf_unique)\n",
    "print(\"o kodikas exei treksei\", len(gdf)/len(gdf_unique), \"fores \\n\")\n",
    "\n",
    "# Check and print the CRS of the GeoDataFrame\n",
    "gdf_unique.set_crs('EPSG:4326', inplace=True)\n",
    "print(\"Coordinate Reference System (CRS):\")\n",
    "print(gdf_unique.crs)\n",
    "\n",
    "# # Define the output GDB path\n",
    "# gdb_path = \"output.gdb\"\n",
    "# layer_name = \"placemarks\"\n",
    "\n",
    "# # Check if the GDB already exists; if not, create the directory\n",
    "# if not os.path.exists(gdb_path):\n",
    "#     os.mkdir(gdb_path)\n",
    "\n",
    "# # Save to the GDB\n",
    "# gdf.to_file(gdb_path, layer=layer_name, driver=\"OpenFileGDB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Συνάρτηση εύρεσης περάσματος δορυφόρου σε ένα συγκεκριμένο σημείο"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observation_times(gdf, latitude, longitude):\n",
    "    # Create a Point object for the given latitude and longitude\n",
    "    point = Point(longitude, latitude)\n",
    "\n",
    "    # List to hold observation times for all matching polygons\n",
    "    observation_info = []\n",
    "\n",
    "    # Ensure the CRS is set for the GeoDataFrame\n",
    "    if gdf.crs is None:\n",
    "        raise ValueError(\"CRS is not set for the GeoDataFrame.\")\n",
    "    \n",
    "    # If the CRS is not EPSG:4326, transform the point\n",
    "    if gdf.crs.to_string() != 'EPSG:4326':\n",
    "        point = gpd.GeoSeries([point], crs='EPSG:4326').to_crs(gdf.crs).iloc[0]\n",
    "\n",
    "    # Search for all polygons that contain the point\n",
    "    for i, row in gdf.iterrows():\n",
    "        if row['geometry'] and row['geometry'].contains(point):\n",
    "            # Append the ObservationTimeStart and ObservationTimeStop to the list\n",
    "            observation_info.append({\n",
    "                'Id': row.get('ID'),\n",
    "                'ObservationTimeStart': row.get('ObservationTimeStart'),\n",
    "                'ObservationTimeStop': row.get('ObservationTimeStop')\n",
    "            })\n",
    "\n",
    "    # If no polygon contains the point, return an empty list\n",
    "    return observation_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 polygons containing the point.\n",
      "Observation info for the point:\n",
      "1. {'Id': '47952-1', 'ObservationTimeStart': '2024-08-27T09:05:50.394', 'ObservationTimeStop': '2024-08-27T09:35:58.002'}\n",
      "2. {'Id': '47995-2', 'ObservationTimeStart': '2024-08-30T09:20:24.973', 'ObservationTimeStop': '2024-08-30T09:42:32.717'}\n",
      "3. {'Id': '48095-1', 'ObservationTimeStart': '2024-09-06T09:05:50.394', 'ObservationTimeStop': '2024-09-06T09:35:58.002'}\n",
      "4. {'Id': '48138-2', 'ObservationTimeStart': '2024-09-09T09:20:24.973', 'ObservationTimeStop': '2024-09-09T09:42:32.717'}\n"
     ]
    }
   ],
   "source": [
    "latitude = 40.89  # Replace with the latitude (φ) of the point you want to check\n",
    "longitude = 24.05  # Replace with the longitude (λ) of the point you want to check\n",
    "\n",
    "\n",
    "observation_info = get_observation_times(gdf_unique, latitude, longitude)\n",
    "\"\"\"\n",
    "if observation_info:\n",
    "    print(\"There are \", len(observation_info), \" polygons containing the point.\")\n",
    "    print(\"Observation info for the point:\", observation_info)\n",
    "\"\"\"\n",
    "if observation_info:\n",
    "    print(\"There are\", len(observation_info), \"polygons containing the point.\")\n",
    "    print(\"Observation info for the point:\")\n",
    "    for i, info in enumerate(observation_info, 1):\n",
    "        print(f\"{i}. {info}\")\n",
    "else:    \n",
    "    print(\"The point is not within any of the polygons.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_praktiki_noa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
